{
  "slug": "workflows/sox-control-testing",
  "title": "SOX control testing evidence runs | Secure Agent Workflow | Claw EA",
  "category": "workflows",
  "html": "<h2>Direct Answer</h2>\n<p>SOX control testing evidence runs are safest when the agent is constrained by a permissioned execution layer, not just instructions in a prompt. Claw EA runs OpenClaw as the baseline agent runtime and adds machine-checkable controls using WPC, CST, gateway receipts, and proof bundles.</p>\n<p>This workflow is designed for the parts auditors care about: repeatable evidence collection, step-up approvals before irreversible actions (export reports, file audit evidence), and a rollback posture with verifiable artifacts you can re-check later.</p>\n\n<h2>Step-by-step runbook</h2>\n<p><strong>1) Define the evidence job as a WPC.</strong> Write a Work Policy Contract (WPC) that lists allowed tools, permitted data classes, redaction rules, and which actions require human approval. Publish the signed WPC to the WPC registry so it can be fetched and verified at runtime.</p>\n<p><strong>2) Issue a CST that is pinned to the policy.</strong> Create a CST (scoped token) via clawscope with a scope hash that matches the intended job boundaries. When you need strong guarantees, pin the CST to the WPC hash so a copied token cannot be reused under a looser policy.</p>\n<p><strong>3) Run the agent under OpenClaw with sandbox and tool policy tightened.</strong> Configure OpenClaw so evidence collection tools run in a sandbox where practical, and explicitly allow only the tools needed for the test. Use OpenClaw’s built-in security audit checks before you enable any external channels or shared workspaces.</p>\n<p><strong>4) Pull evidence via official APIs or MCP server, not ad hoc browsing.</strong> For system-of-record evidence (ERP, ticketing, GRC, IAM), retrieve artifacts via official API or via an MCP server you control, then store them as immutable inputs to the run. If Microsoft 365 is in scope, treat Microsoft Graph permissions/scopes and Conditional Access as part of the run’s prerequisites, and keep privileged access behind PIM-based activation.</p>\n<p><strong>5) Enforce step-up approvals on irreversible actions.</strong> When the agent reaches an irreversible step like exporting a report or filing audit evidence, require a human approval checkpoint that includes a preview of what will be exported and where it will be stored. The approval should be recorded as part of the run metadata so you can show who authorized the action and under which WPC.</p>\n<p><strong>6) Apply DLP and redaction before any outbound write.</strong> Treat generated narratives, exported PDFs, and attachments as potentially sensitive even if the source is “internal.” Redact secrets and identifiers per the WPC, and keep a hash of the unredacted original only if your retention policy allows it.</p>\n<p><strong>7) Close the run with a proof bundle and retention decisions.</strong> At completion, produce a proof bundle that includes gateway receipts for model calls, policy identifiers, and run metadata needed for later verification. Store the bundle in your evidence repository and optionally publish a Trust Pulse for easier audit viewing, while keeping the underlying artifacts in your controlled storage.</p>\n\n<h2>Threat model</h2>\n<p>SOX evidence runs fail in predictable ways: over-broad access, replayed runs, and evidence tampering after the fact. The goal is to make the run deterministic enough to repeat, and bounded enough to stop damage when the agent is wrong.</p>\n<table>\n  <thead>\n    <tr>\n      <th>Threat</th>\n      <th>What happens</th>\n      <th>Control</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Prompt-only “policy” drift</td>\n      <td>The agent follows updated chat instructions that expand scope, export extra data, or change the evidence narrative.</td>\n      <td>Use a signed WPC and pin the CST to the WPC hash; the runtime enforces what tools and actions are allowed, regardless of what a prompt says.</td>\n    </tr>\n    <tr>\n      <td>Replay of a prior token or run context</td>\n      <td>A CST is reused to rerun evidence collection later, potentially against different data or in a different environment.</td>\n      <td>Use marketplace anti-replay binding with job-scoped CST binding; require per-job tokens and fail closed if the token is not bound to the job.</td>\n    </tr>\n    <tr>\n      <td>Irreversible evidence actions without review</td>\n      <td>The agent exports a report, uploads attachments, or files audit evidence with incorrect period, entity, or population.</td>\n      <td>Step-up approvals for export and filing actions; the WPC should mark these as deny-by-default unless a human approval flag is present.</td>\n    </tr>\n    <tr>\n      <td>Data leakage in narratives and attachments</td>\n      <td>Sensitive data is embedded in a generated summary or an exported file, then shared externally or stored too broadly.</td>\n      <td>DLP and redaction rules in the WPC; keep outputs restricted and redact before outbound writes. Treat evidence packaging as a separate step with its own controls.</td>\n    </tr>\n    <tr>\n      <td>Disputed evidence provenance</td>\n      <td>You cannot show which model calls were made, what policy was in effect, or whether outputs were edited after generation.</td>\n      <td>Route model calls through clawproxy to emit gateway receipts, then bundle them into a proof bundle with policy hash references for later verification.</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>Policy-as-code example</h2>\n<p>This is a compact, JSON-like policy sketch you can adapt into a WPC. The important parts are: explicit tool boundaries, step-up approvals on irreversible actions, DLP and redaction rules, and evidence retention and replay posture.</p>\n<pre>{\n  \"wpc_version\": \"1\",\n  \"job_type\": \"sox_control_testing_evidence_run\",\n  \"scope\": {\n    \"control_ids\": [\"ITGC-AC-01\", \"ITGC-CHG-03\"],\n    \"period\": {\"from\": \"2026-01-01\", \"to\": \"2026-01-31\"},\n    \"entities\": [\"US-Prod\"]\n  },\n  \"tools\": {\n    \"allow\": [\n      \"read_only_api_client\",\n      \"evidence_packager\",\n      \"model_via_clawproxy\"\n    ],\n    \"deny\": [\"shell\", \"write_filesystem_outside_workspace\", \"browser_remote_control\"]\n  },\n  \"approvals\": {\n    \"required_for\": [\n      {\"action\": \"export_report\", \"reason\": \"irreversible\"},\n      {\"action\": \"file_audit_evidence\", \"reason\": \"irreversible\"}\n    ],\n    \"approval_payload_must_include\": [\"destination\", \"period\", \"entity\", \"artifact_list_hash\"]\n  },\n  \"dlp\": {\n    \"redact\": [\"secrets\", \"access_tokens\", \"government_id\", \"bank_account\"],\n    \"allow_pii\": \"deny_by_default\",\n    \"output_label\": \"SOX-EVIDENCE-CONFIDENTIAL\"\n  },\n  \"replay_and_retention\": {\n    \"token_policy\": {\"cst_scope_hash_required\": true, \"policy_hash_pinning\": true},\n    \"anti_replay\": {\"job_scoped_binding\": true},\n    \"retain_proof_bundle_days\": 365,\n    \"retain_raw_artifacts_days\": 90,\n    \"rollback\": {\"do_not_delete_prior_evidence_packages\": true}\n  }\n}</pre>\n\n<h2>What proof do you get?</h2>\n<p>Every model call routed through clawproxy produces gateway receipts. Those receipts are designed to be verified later, so you can show that a specific set of calls occurred under a specific job context instead of relying on screenshots of chat logs.</p>\n<p>Claw EA packages gateway receipts, policy references (including the WPC hash), token binding metadata, and run identifiers into a proof bundle. The proof bundle is the unit you hand to audit, or re-verify internally, when someone asks “what exactly happened in this evidence run?”</p>\n<p>If you need a shareable audit view, you can store a Trust Pulse artifact for the run so reviewers can find the proof bundle quickly. Treat Trust Pulse as the index and viewer, and keep your raw evidence files in your own controlled repository with your retention rules.</p>\n\n<h2>Rollback posture</h2>\n<p>Rollback for SOX evidence runs is mostly about preventing destructive changes and making corrections traceable. You should assume any export or filing step is irreversible and design the run so the “rollback” action is to supersede, not erase.</p>\n<table>\n  <thead>\n    <tr>\n      <th>Action</th>\n      <th>Safe rollback</th>\n      <th>Evidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Draft evidence narrative generated</td>\n      <td>Regenerate under the same WPC and period scope; keep the prior draft as superseded, not deleted.</td>\n      <td>Proof bundle containing gateway receipts and run metadata, plus hashes of drafts stored in your repository.</td>\n    </tr>\n    <tr>\n      <td>Export report (high risk)</td>\n      <td>Export a corrected report with a new run id; mark the prior export as voided in your evidence index.</td>\n      <td>Human approval record plus proof bundle; artifact hashes for both exports and the voiding note.</td>\n    </tr>\n    <tr>\n      <td>File audit evidence (high risk)</td>\n      <td>File an amendment package that references the prior submission; do not attempt deletion unless your GRC system supports it with an audit trail.</td>\n      <td>Approval payload, destination metadata, and proof bundle linking the filing step to the WPC and job-scoped CST binding.</td>\n    </tr>\n    <tr>\n      <td>DLP redaction applied</td>\n      <td>Re-run packaging with updated redaction rules; preserve the old package with restricted access and a deprecation note.</td>\n      <td>Two packages with distinct hashes; WPC revisions recorded so you can explain why redaction changed.</td>\n    </tr>\n  </tbody>\n</table>\n<p>Optional controls that can be implemented in an enterprise buildout include egress allowlists enforced outside clawproxy and automatic cost budget enforcement. Keep them separate from the core proof path so verification still works when those controls evolve.</p>\n\n<h2>FAQ</h2>\n<h3>Why is prompt-only governance not enough for SOX evidence runs?</h3>\n<p>A prompt is editable and hard to enforce, especially when the agent encounters new data or conflicting instructions. A WPC makes the allowed actions and data handling rules machine-checkable and stable across reruns, and CST policy hash pinning helps prevent “same token, different behavior.”</p>\n\n<h3>What makes an action “irreversible” in this workflow?</h3>\n<p>Exports and filings create records outside the agent’s workspace and often trigger retention or distribution rules you cannot undo cleanly. Treat export reports and file audit evidence as high risk, require step-up approval, and record the approval inputs in the run metadata.</p>\n\n<h3>Can we run this without giving the agent broad system access?</h3>\n<p>Yes, that is the point. Keep data access read-only where possible, restrict tools via OpenClaw tool policy, and isolate execution with sandboxing for collection and packaging steps.</p>\n\n<h3>How do auditors verify the run?</h3>\n<p>They review the WPC that defined permitted actions, then check the proof bundle produced by the run. Gateway receipts provide a tamper-evident record of model calls routed through clawproxy, and the job-scoped CST binding reduces replay risk.</p>\n\n<h3>Where do we store evidence files versus proof artifacts?</h3>\n<p>Store raw evidence files and exports in your controlled evidence repository with your retention schedule. Store proof bundles and any Trust Pulse entries as the verification layer that explains how the evidence was produced and under which constraints.</p>\n\n<h2>Sources</h2>\n<ul>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/security/index.md\">OpenClaw Gateway Security (audit + footguns)</a></li>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/sandbox-vs-tool-policy-vs-elevated.md\">OpenClaw: Sandbox vs Tool Policy vs Elevated</a></li>\n  <li><a href=\"https://cloud.google.com/transform/how-google-does-it-using-binary-authorization-to-boost-supply-chain-security\">Google Cloud Blog: Using Binary Authorization to boost supply chain security</a></li>\n  <li><a href=\"https://aws.amazon.com/solutions/guidance/automating-background-checks-for-reporting-and-audits-on-aws\">AWS Guidance for Automating Background Checks for Reporting &amp; Audits on AWS</a></li>\n</ul>\n\n<div class=\"cta-banner\" data-cta=\"bofu-endcap\">\n  <h2>Ready to put this workflow into production?</h2>\n  <p>Get a scoped deployment plan with Work Policy Contracts, approval gates, and cryptographic proof bundles for your team.</p>\n  <a href=\"/contact\" class=\"cta-btn cta-btn-lg\" data-cta=\"bofu-talk-to-sales\">Talk to Sales</a>\n  <a href=\"/trust\" class=\"cta-btn cta-btn-outline cta-btn-lg\" style=\"margin-left:.75rem\" data-cta=\"bofu-trust-layer\">Review Trust Layer</a>\n</div>\n",
  "description": "SOX control testing evidence runs are safest when the agent is constrained by a permissioned execution layer, not just instructions in a prompt. Claw EA runs OpenClaw as the baseline agent runtime and adds machine-checka",
  "faqs": [
    {
      "q": "Why is prompt-only governance not enough for SOX evidence runs?",
      "a": "A prompt is editable and hard to enforce, especially when the agent encounters new data or conflicting instructions. A WPC makes the allowed actions and data handling rules machine-checkable and stable across reruns, and CST policy hash pinning helps prevent “same token, different behavior.”"
    },
    {
      "q": "What makes an action “irreversible” in this workflow?",
      "a": "Exports and filings create records outside the agent’s workspace and often trigger retention or distribution rules you cannot undo cleanly. Treat export reports and file audit evidence as high risk, require step-up approval, and record the approval inputs in the run metadata."
    },
    {
      "q": "Can we run this without giving the agent broad system access?",
      "a": "Yes, that is the point. Keep data access read-only where possible, restrict tools via OpenClaw tool policy, and isolate execution with sandboxing for collection and packaging steps."
    },
    {
      "q": "How do auditors verify the run?",
      "a": "They review the WPC that defined permitted actions, then check the proof bundle produced by the run. Gateway receipts provide a tamper-evident record of model calls routed through clawproxy, and the job-scoped CST binding reduces replay risk."
    },
    {
      "q": "Where do we store evidence files versus proof artifacts?",
      "a": "Store raw evidence files and exports in your controlled evidence repository with your retention schedule. Store proof bundles and any Trust Pulse entries as the verification layer that explains how the evidence was produced and under which constraints."
    }
  ],
  "sources": [
    {
      "title": "Guidance for Automating Background Checks for Reporting & Audits on AWS",
      "uri": "https://aws.amazon.com/solutions/guidance/automating-background-checks-for-reporting-and-audits-on-aws"
    },
    {
      "title": "How Google Does It: Using Binary Authorization to boost supply ...",
      "uri": "https://cloud.google.com/transform/how-google-does-it-using-binary-authorization-to-boost-supply-chain-security"
    },
    {
      "title": "SOC 2 Report - Einstein Platform and Agentforce on Hyperforce",
      "uri": "https://compliance.salesforce.com/en/documents/a006e0000115nJkAAI"
    },
    {
      "title": "What Are Agentic Workflows?",
      "uri": "https://www.salesforce.com/agentforce/agentic-workflows/"
    },
    {
      "title": "Data Cloud Governance: Protecting Your Data in the Agentic Landscape",
      "uri": "https://admin.salesforce.com/blog/2025/data-cloud-governance-protecting-your-data-agentforce"
    }
  ],
  "model": "candidate-01",
  "generatedAt": "2026-02-11T11:50:55.387Z",
  "indexable": true
}