{
  "slug": "audit/replay-and-rollback",
  "title": "Replay and Rollback for Agent Actions | Claw EA",
  "category": "audit",
  "html": "<p>Replay for agent actions is only trustworthy when you can bind “what the agent was allowed to do” to “what it actually did”, and verify both later. In Claw EA, OpenClaw is the baseline agent runtime, and Claw Bureau primitives make replays and rollbacks auditable via WPC, CST, gateway receipts, and proof bundles.</p>\n<p>Prompt-only controls are not enough because they are not enforceable at execution time and do not create a stable artifact you can verify after an incident. A permissioned execution layer with policy-as-code lets you deny unsafe tool calls, pin allowed scopes, and produce evidence that survives log rotation and human memory.</p>\n\n<h2>Step-by-step runbook</h2>\n<ol>\n  <li>\n    <p><strong>Define the action boundary you want to be able to replay.</strong> Split “model calls and tool calls” from “external side effects” (API writes, emails, deployments). You can replay the former deterministically enough for audit, but the latter must be treated as non-idempotent unless the target system supports idempotency keys or a dedicated replay mechanism via official API.</p>\n  </li>\n  <li>\n    <p><strong>Write a WPC that encodes the allowed tools, model routing, and scope constraints.</strong> Treat the WPC as the contract you will show an auditor later, not a suggestion for the agent. Keep it narrow, and version it by hash so you can prove exactly what was in force at the time.</p>\n  </li>\n  <li>\n    <p><strong>Issue a CST that is job-scoped, and pin it to the policy hash when you need strict replay semantics.</strong> A job-scoped CST reduces replay risk because captured tokens do not remain broadly useful. Policy hash pinning makes “same token, different policy” invalid, which matters when you are trying to reproduce a run under the original constraints.</p>\n  </li>\n  <li>\n    <p><strong>Route model traffic through clawproxy to get gateway receipts.</strong> This is where you get signed evidence of model inputs and outputs at the gateway boundary, including enough metadata to verify ordering and association to a job. If you use OpenRouter via fal, keep it behind clawproxy so receipts are emitted consistently.</p>\n  </li>\n  <li>\n    <p><strong>Package artifacts into a proof bundle and store it with the run record.</strong> Include the WPC hash, CST scope hash, gateway receipts, and the minimal runtime metadata required to verify context without storing secrets. If you need shared viewing, store or mirror the bundle as a Trust Pulse for audit access.</p>\n  </li>\n  <li>\n    <p><strong>Verify before you replay.</strong> Recompute hashes, validate signatures on gateway receipts, and ensure the CST binding matches the job you are attempting to reproduce. Fail closed if the policy hash, scope hash, or receipt chain does not match what was recorded.</p>\n  </li>\n  <li>\n    <p><strong>Replay in an isolated environment, then roll forward with explicit approvals.</strong> For tool execution, prefer sandboxed runs in OpenClaw so the replay cannot mutate production state. If a replay identifies required rollback actions, execute rollback as a separate, permissioned job with its own WPC and CST.</p>\n  </li>\n</ol>\n\n<h2>Threat model</h2>\n<p>Replay and rollback are most often broken by missing boundaries: logs that are editable, policies that are not pinned, or side effects that cannot be reconstructed. The table below focuses on concrete failure modes and the operational control you can apply in Claw EA with OpenClaw plus Claw Bureau primitives.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Threat</th>\n      <th>What happens</th>\n      <th>Control</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Token replay against a new job</td>\n      <td>An attacker reuses a captured token to rerun tools or model calls outside the intended run.</td>\n      <td>Use job-scoped CST binding (anti-replay) and keep CST TTL short. For strict cases, pin CST to the WPC hash so policy drift makes reuse fail.</td>\n    </tr>\n    <tr>\n      <td>Policy drift between original run and replay</td>\n      <td>You “replay” using today’s permissions, which can hide how the incident happened or widen damage.</td>\n      <td>Record and verify the WPC hash in the proof bundle. Require replays to reference the exact WPC and fail closed if the hash does not match.</td>\n    </tr>\n    <tr>\n      <td>Receipt gaps or partial logging</td>\n      <td>Model calls occurred outside the gateway, so you cannot prove what the model saw or returned.</td>\n      <td>Route model calls through clawproxy and require gateway receipts for the job. Treat missing receipts as an incomplete audit trail and block “verified replay” status.</td>\n    </tr>\n    <tr>\n      <td>Non-idempotent external side effects</td>\n      <td>Replaying causes double writes, duplicate emails, or repeated financial actions.</td>\n      <td>Do not treat external writes as replayable unless the target supports idempotency via official API. Prefer “simulate replay” for analysis, then do rollback with a separate, explicitly approved job.</td>\n    </tr>\n    <tr>\n      <td>Prompt-only “policy” bypass</td>\n      <td>The agent is socially engineered to ignore instructions, and then performs real tool actions.</td>\n      <td>Enforce policy at execution time with policy-as-code, not in the prompt. In OpenClaw, pair tool allow/deny and sandboxing with WPC-based constraints so the agent cannot exceed the contract.</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>Policy-as-code example</h2>\n<p>This example illustrates the shape of a permissioned contract you can verify later. The WPC is the signed artifact, identified by its hash, and referenced by the job so a replay can prove the same constraints were in force.</p>\n\n<pre>\n{\n  \"wpc_version\": \"v1\",\n  \"policy_name\": \"audit-safe-replay\",\n  \"model_routing\": {\n    \"provider\": \"openrouter_via_fal\",\n    \"must_use_gateway_receipts\": true\n  },\n  \"tools\": {\n    \"allow\": [\"read\", \"search\", \"http_get_via_mcp_server\"],\n    \"deny\": [\"exec\", \"write\", \"email_send\", \"deploy\"]\n  },\n  \"cst_requirements\": {\n    \"job_scoped\": true,\n    \"scope_hash_required\": true,\n    \"policy_hash_pinned\": true\n  },\n  \"retention\": {\n    \"proof_bundle_required\": true,\n    \"store_as_trust_pulse\": \"optional\"\n  }\n}\n</pre>\n\n<p>Two operational notes: first, deny rules must be enforced by the execution layer, not requested in the prompt. Second, any tool that can mutate state should be treated as a separate class of job with approvals, even if you later decide to allow it in a tightly scoped WPC.</p>\n\n<h2>What proof do you get?</h2>\n<p>Claw EA evidence is built around verifiable artifacts, not “trust me” logs. The WPC is signed and hash-addressed, the CST carries a scope hash and can be pinned to a policy hash, and gateway receipts are signed at the model gateway boundary.</p>\n\n<p>A proof bundle is the harness artifact that packages those elements so you can hand it to an auditor or use it for internal incident review. If you choose, you can store or share the resulting run artifact via Trust Pulse for audit viewing.</p>\n\n<p>Here is a simplified “shape” of what a bundle might contain (illustrative, not an API contract):</p>\n<pre>\n{\n  \"job\": { \"id\": \"job_123\", \"started_at\": \"2026-02-11T01:02:03Z\" },\n  \"wpc\": { \"policy_hash\": \"b64u:...\", \"issuer\": \"clawcontrols\" },\n  \"cst\": { \"scope_hash\": \"b64u:...\", \"job_binding\": \"job_123\" },\n  \"gateway_receipts\": [\n    {\n      \"receipt_id\": \"rcpt_001\",\n      \"gateway\": \"clawproxy\",\n      \"model\": \"openrouter/*\",\n      \"request_hash\": \"b64u:...\",\n      \"response_hash\": \"b64u:...\",\n      \"signature\": \"ed25519:...\"\n    }\n  ],\n  \"runtime\": { \"agent_runtime\": \"openclaw\", \"session\": \"agent:main:main\" },\n  \"artifacts\": { \"bundle_hash\": \"b64u:...\" }\n}\n</pre>\n\n<p>What is replayable: the sequence of model calls covered by gateway receipts, and the tool decisions recorded by the harness when tools are executed under the same WPC. What is not replayable by default: external side effects unless the external system provides replay, event archive, or idempotent write semantics via official API.</p>\n\n<h2>Rollback posture</h2>\n<p>Rollback is not “undo everything the agent did” unless you designed the environment for reversibility. The practical stance is to separate analysis replay from corrective actions, and require the corrective job to be permissioned and evidenced just like the original run.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Action</th>\n      <th>Safe rollback</th>\n      <th>Evidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Model call produced a bad recommendation</td>\n      <td>No rollback needed; replay for analysis and update WPC/tool policy to prevent execution without approval.</td>\n      <td>Gateway receipts show exact prompt/response hashes and ordering, with signatures from clawproxy.</td>\n    </tr>\n    <tr>\n      <td>Tool read-only action (query, fetch)</td>\n      <td>Typically no rollback; use replay to reproduce what data was accessed and when.</td>\n      <td>Proof bundle includes WPC hash and CST scope hash to show access was within contract.</td>\n    </tr>\n    <tr>\n      <td>State-changing external write (ticket update, email, deploy)</td>\n      <td>Rollback as a separate job that calls the vendor’s official API with explicit approval and idempotency where available.</td>\n      <td>Two bundles: original run bundle and rollback run bundle, each with its own WPC and gateway receipts.</td>\n    </tr>\n    <tr>\n      <td>Suspected credential exposure in logs</td>\n      <td>Revoke CST, rotate external secrets, and reduce future collection by tightening OpenClaw logging redaction and tool permissions.</td>\n      <td>Revocation records plus the original proof bundle to scope impact; OpenClaw security audit output can be attached as supporting context.</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>FAQ</h2>\n<h3>What can I actually replay for an agent run?</h3>\n<p>You can replay the decision trail and model interactions that are covered by gateway receipts, plus tool execution that was mediated under the same WPC and environment. You cannot safely replay external side effects unless the external system supports replay or idempotent writes via official API.</p>\n\n<h3>Why is prompt-only policy insufficient for audit and rollback?</h3>\n<p>A prompt is not an enforcement point and can be ignored or manipulated. Policy-as-code is enforced at execution time, and its hash can be pinned to the job so later verification proves what constraints were active.</p>\n\n<h3>How do WPC and CST help with anti-replay?</h3>\n<p>The WPC hash gives you an immutable identifier for the allowed behavior. A job-scoped CST binding reduces the blast radius of token capture, and policy hash pinning prevents a valid token from being reused under a different policy.</p>\n\n<h3>What is the minimum evidence set I should retain?</h3>\n<p>At minimum: WPC hash, CST scope hash, and gateway receipts for all model calls, packaged as a proof bundle. If you need cross-team audit viewing, store the artifact as a Trust Pulse.</p>\n\n<h3>How does this relate to OpenClaw sandboxing and tool policy?</h3>\n<p>OpenClaw controls where tools run and which tools are callable, which limits blast radius during replay and rollback. Claw EA adds portable, verifiable artifacts around those decisions so you can prove what happened, not just describe it.</p>\n\n<h2>Sources</h2>\n<ul>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/security/index.md\">OpenClaw Gateway Security (audit + footguns)</a></li>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/sandbox-vs-tool-policy-vs-elevated.md\">OpenClaw: Sandbox vs Tool Policy vs Elevated</a></li>\n  <li><a href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-archive.html\">Archiving and replaying events in Amazon EventBridge</a></li>\n  <li><a href=\"https://learn.microsoft.com/en-us/microsoft-copilot-studio/authoring-review-activity\">Review agent activity - Microsoft Copilot Studio</a></li>\n  <li><a href=\"https://aos.owasp.org/spec/trace/events\">Supported Events - Agent Observability Standard (AOS)</a></li>\n</ul>",
  "description": "Replay for agent actions is only trustworthy when you can bind “what the agent was allowed to do” to “what it actually did”, and verify both later. In Claw EA, OpenClaw is the baseline agent runtime, and Claw Bureau prim",
  "faqs": [
    {
      "q": "What can I actually replay for an agent run?",
      "a": "You can replay the decision trail and model interactions that are covered by gateway receipts, plus tool execution that was mediated under the same WPC and environment. You cannot safely replay external side effects unless the external system supports replay or idempotent writes via official API."
    },
    {
      "q": "Why is prompt-only policy insufficient for audit and rollback?",
      "a": "A prompt is not an enforcement point and can be ignored or manipulated. Policy-as-code is enforced at execution time, and its hash can be pinned to the job so later verification proves what constraints were active."
    },
    {
      "q": "How do WPC and CST help with anti-replay?",
      "a": "The WPC hash gives you an immutable identifier for the allowed behavior. A job-scoped CST binding reduces the blast radius of token capture, and policy hash pinning prevents a valid token from being reused under a different policy."
    },
    {
      "q": "What is the minimum evidence set I should retain?",
      "a": "At minimum: WPC hash, CST scope hash, and gateway receipts for all model calls, packaged as a proof bundle. If you need cross-team audit viewing, store the artifact as a Trust Pulse."
    },
    {
      "q": "How does this relate to OpenClaw sandboxing and tool policy?",
      "a": "OpenClaw controls where tools run and which tools are callable, which limits blast radius during replay and rollback. Claw EA adds portable, verifiable artifacts around those decisions so you can prove what happened, not just describe it."
    }
  ],
  "sources": [
    {
      "title": "Supported Events - Agent Observability Standard",
      "uri": "https://aos.owasp.org/spec/trace/events"
    },
    {
      "title": "Review agent activity - Microsoft Copilot Studio",
      "uri": "https://learn.microsoft.com/en-us/microsoft-copilot-studio/authoring-review-activity"
    },
    {
      "title": "Archiving and replaying events in Amazon EventBridge",
      "uri": "https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-archive.html"
    },
    {
      "title": "Archiving and replaying events with Amazon EventBridge | Amazon Web Services",
      "uri": "https://aws.amazon.com/blogs/compute/archiving-and-replaying-events-with-amazon-eventbridge"
    },
    {
      "title": "Agentic Patterns and Implementation with Agentforce",
      "uri": "https://architect.salesforce.com/fundamentals/agentic-patterns"
    },
    {
      "title": "TapeAgents: a Holistic Framework for Agent Development and Optimization",
      "uri": "https://www.servicenow.com/research/publication/dzmitry-bahdanau-tape-arxiv2024.html"
    }
  ],
  "model": "candidate-01",
  "generatedAt": "2026-02-11T11:24:27.770Z",
  "indexable": true
}