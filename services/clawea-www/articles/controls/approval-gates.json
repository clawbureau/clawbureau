{
  "slug": "controls/approval-gates",
  "title": "Step-up approvals (human-in-the-loop) for Agents | Policy-as-Code Control | Claw EA",
  "category": "controls",
  "html": "<p>Step-up approvals (human-in-the-loop) are a policy-as-code gate that pauses an OpenClaw-run agent right before a high-risk tool action and requires an explicit human “approve/deny” decision. The approval is enforced at the execution layer, so the agent cannot bypass it with prompting, tool rephrasing, or multi-step indirection.</p>\n<p>In Claw EA, the gate is expressed as a WPC and bound to the run using a CST. When the agent calls models through clawproxy, gateway receipts and a proof bundle capture what was requested, what was approved, and what was actually executed.</p>\n\n<h2>Step-by-step runbook</h2>\n<p>This runbook assumes OpenClaw is your baseline agent runtime and you want approvals on specific tool classes (payments, identity changes, production deploys, outbound email, destructive file actions). You can implement the approver UI via your existing ticketing or chat workflow via official API, via MCP server, or via enterprise buildout.</p>\n<ol>\n  <li>\n    <p><strong>Pick the “step-up” boundary.</strong> Define which tool calls require approval (for example: exec with write access, outbound network posts, “send email”, “create user”, “delete”, “refund”). Keep the rule tool-centric, not prompt-centric, because tools are the point where impact happens.</p>\n  </li>\n  <li>\n    <p><strong>Write the approval gate into a WPC.</strong> Store the WPC in the WPC registry so it is signed and hash-addressed. Treat the WPC hash as the immutable control reference you can point audits at.</p>\n  </li>\n  <li>\n    <p><strong>Issue a CST that pins the policy.</strong> Use a CST (issued by clawscope) with scope hash and optional policy hash pinning so the run is cryptographically bound to the WPC. If the policy changes later, old runs still verify against the pinned hash.</p>\n  </li>\n  <li>\n    <p><strong>Enforce the gate inside the tool boundary.</strong> In OpenClaw, combine tool policy and sandboxing: restrict which tools exist and where they run, then add a step-up hook for the “dangerous” tools. Avoid “prompt-only approvals” (for example: “Ask the user before deleting”) because an injected prompt can suppress or simulate consent.</p>\n  </li>\n  <li>\n    <p><strong>Route model calls through clawproxy.</strong> When the agent uses OpenRouter via fal routed through clawproxy, you get gateway receipts for model calls. These receipts let you prove what the model saw and returned at each decision point that led up to an approval request.</p>\n  </li>\n  <li>\n    <p><strong>Record approval decisions as run artifacts.</strong> Store the approver identity, timestamp, decision, and the exact “approval payload” (the structured request describing what will happen if approved). Include a hash of the payload in the run log so approvals are bound to specific actions and cannot be replayed for different actions.</p>\n  </li>\n  <li>\n    <p><strong>Bundle and verify after the run.</strong> Emit a proof bundle that includes the WPC reference, CST metadata, gateway receipts, and the approval artifacts. Optionally publish the resulting audit view as a Trust Pulse for reviewers.</p>\n  </li>\n</ol>\n\n<h2>Threat model</h2>\n<p>Step-up approvals are not about making agents “polite”. They are about preventing a model, a plugin, or an operator mistake from turning into an irreversible side effect without human intent.</p>\n<table>\n  <thead>\n    <tr>\n      <th>Threat</th>\n      <th>What happens</th>\n      <th>Control</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Prompt injection triggers a destructive tool action</td>\n      <td>The agent is convinced to run delete, rotate secrets, exfiltrate data, or message external parties.</td>\n      <td>Execution-layer approval gate on the tool call, not on the prompt. OpenClaw tool policy restricts tool availability; sandboxing reduces blast radius.</td>\n    </tr>\n    <tr>\n      <td>Tool indirection and multi-step “approval bypass”</td>\n      <td>The agent avoids the “delete” tool by using exec to run a deletion command, or uses a different API path.</td>\n      <td>Gate by capability class (exec, write, network post, identity mutation) and enforce at the tool boundary. Prefer deny-by-default tool policy plus explicit allowlist.</td>\n    </tr>\n    <tr>\n      <td>Replay of an old approval on a new action</td>\n      <td>An attacker reuses a prior “approved” decision blob to authorize a different action.</td>\n      <td>Bind approvals to a hashed approval payload and job-scoped CST binding (marketplace anti-replay binding). Store the payload hash in the proof bundle.</td>\n    </tr>\n    <tr>\n      <td>Human approves without seeing the real delta</td>\n      <td>Approver clicks “yes” on a vague request, missing sensitive scope such as production target or recipient list.</td>\n      <td>Require structured approval payloads: exact command, exact recipients, target resource identifiers, and a computed diff preview when possible. Reject approvals that lack required fields.</td>\n    </tr>\n    <tr>\n      <td>Dispute after the fact</td>\n      <td>Team cannot prove what the model was asked, what it responded, and why an approval was requested.</td>\n      <td>Gateway receipts from clawproxy for model calls plus a proof bundle that ties receipts, WPC hash, and approval artifacts together.</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>Policy-as-code example</h2>\n<p>This is a compact JSON-like sketch of an approval gate WPC. It shows a deny-by-default approach where certain tool classes require step-up approval, and approvals must reference a specific payload hash.</p>\n<pre>\n{\n  \"wpc_version\": \"v1\",\n  \"policy_name\": \"approval-gates-prod\",\n  \"tool_policy\": {\n    \"default\": \"deny\",\n    \"allow\": [\n      \"read\", \"search\", \"safe_http_get\"\n    ],\n    \"step_up_approval_required\": [\n      { \"tool\": \"exec\", \"constraints\": { \"workspaceAccess\": \"rw\" } },\n      { \"tool\": \"write\" },\n      { \"tool\": \"http_post\" },\n      { \"tool\": \"send_email\" },\n      { \"tool\": \"identity_mutation\" }\n    ]\n  },\n  \"approval_gate\": {\n    \"required_fields\": [\"action_type\", \"target\", \"parameters\", \"payload_hash\"],\n    \"approval_ttl_seconds\": 900,\n    \"bind_to_job\": true\n  }\n}\n</pre>\n<p>In practice, you store the signed artifact as a WPC and distribute only the hash reference. The CST can optionally pin the WPC hash so the runtime must fetch and verify the exact policy artifact before executing.</p>\n\n<h2>What proof do you get?</h2>\n<p>For every gated action, you want evidence that (1) the policy required approval, (2) a human made a decision on a specific payload, and (3) the runtime executed only what was approved. Claw EA focuses on artifacts you can verify later, without trusting a single app log.</p>\n<p>Concretely, you get gateway receipts for model calls emitted by clawproxy, which let you reconstruct the model interaction leading to an approval request. You also get a proof bundle that ties together the WPC reference, CST metadata, approval request and decision artifacts, and the relevant gateway receipts for audit and verification.</p>\n<p>If you publish to Trust Pulse, reviewers get a consistent place to view the policy hash, the approval trail, and the verified receipt chain. This helps answer operational questions like “which approver authorized this outbound message?” and “did the model output change after approval was granted?”.</p>\n\n<h2>Rollback posture</h2>\n<p>Approvals reduce the chance of an incident, but you still need a clean rollback plan. The key is to design your tools so high-impact operations are reversible or at least bounded, then require step-up approval for the irreversible ones.</p>\n<table>\n  <thead>\n    <tr>\n      <th>Action</th>\n      <th>Safe rollback</th>\n      <th>Evidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Outbound email or chat message</td>\n      <td>Prefer “draft only” mode by default; require approval to send. If sent, send a follow-up correction and open an incident ticket.</td>\n      <td>Approval payload includes recipients and message body hash; proof bundle shows the approval decision and the tool call that actually sent.</td>\n    </tr>\n    <tr>\n      <td>File write or config change</td>\n      <td>Write to a branch or staging path; require approval to merge or apply. If applied, revert via known-good snapshot.</td>\n      <td>Approval payload includes path list and diff hash; OpenClaw sandbox mode plus tool policy reduces host impact; proof bundle ties it together.</td>\n    </tr>\n    <tr>\n      <td>Exec on host or elevated mode</td>\n      <td>Avoid by default; require explicit step-up and narrow command allowlist. If executed, rotate credentials and isolate affected hosts.</td>\n      <td>Approval payload captures command, args, working directory, and environment redaction policy; gateway receipts show the model plan that led to escalation.</td>\n    </tr>\n    <tr>\n      <td>Identity or permission mutation</td>\n      <td>Use time-bound changes where possible; otherwise log the “before” state and provide a revert playbook.</td>\n      <td>Approval payload includes target principal and permission identifiers; proof bundle records who approved and when.</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>FAQ</h2>\n\n<h3>Why not just tell the agent “always ask before doing X”?</h3>\n<p>Because that is a prompt instruction, not a permission boundary. Prompt injection and tool indirection can cause the agent to skip, fake, or reinterpret the request, while an execution-layer gate can block the tool call until a real approval artifact exists.</p>\n\n<h3>Where should the approval gate be enforced?</h3>\n<p>Enforce it at the point where the tool would execute, not in the chat UI. OpenClaw already distinguishes tool policy and sandboxing from “skills” text, and that separation is where approval checks belong.</p>\n\n<h3>How do you bind an approval to the exact action being taken?</h3>\n<p>Use a structured approval payload and include a payload hash in both the approval artifact and the run record. Pair that with job-scoped CST binding to reduce replay risk across runs.</p>\n\n<h3>What do auditors get that they can independently verify?</h3>\n<p>They can verify the WPC hash reference, validate gateway receipts for model calls emitted by clawproxy, and review a proof bundle that links receipts and approval decisions to the run. This is stronger than a screenshot or a single system log because it preserves the chain of custody across the model boundary.</p>\n\n<h3>Can this work with Microsoft approval experiences?</h3>\n<p>Yes, you can route the human decision through a Microsoft approval flow via official API, then store the decision artifact and payload hash back into the run record. Keep the enforcement in the agent execution layer so the external approval system is an input, not the control boundary.</p>\n\n<h2>Sources</h2>\n<ul>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/sandbox-vs-tool-policy-vs-elevated.md\">OpenClaw: Sandbox vs Tool Policy vs Elevated</a></li>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/security/index.md\">OpenClaw Gateway Security</a></li>\n  <li><a href=\"https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/human-in-the-loop\">Human-in-the-Loop with AG-UI (Microsoft Learn)</a></li>\n  <li><a href=\"https://learn.microsoft.com/en-us/microsoft-copilot-studio/flows-advanced-approvals\">Multistage and AI approvals in agent flows (Microsoft Learn)</a></li>\n</ul>",
  "description": "Step-up approvals (human-in-the-loop) are a policy-as-code gate that pauses an OpenClaw-run agent right before a high-risk tool action and requires an explicit human “approve/deny” decision. The approval is enforced at t",
  "faqs": [
    {
      "q": "Why not just tell the agent “always ask before doing X”?",
      "a": "Because that is a prompt instruction, not a permission boundary. Prompt injection and tool indirection can cause the agent to skip, fake, or reinterpret the request, while an execution-layer gate can block the tool call until a real approval artifact exists."
    },
    {
      "q": "Where should the approval gate be enforced?",
      "a": "Enforce it at the point where the tool would execute, not in the chat UI. OpenClaw already distinguishes tool policy and sandboxing from “skills” text, and that separation is where approval checks belong."
    },
    {
      "q": "How do you bind an approval to the exact action being taken?",
      "a": "Use a structured approval payload and include a payload hash in both the approval artifact and the run record. Pair that with job-scoped CST binding to reduce replay risk across runs."
    },
    {
      "q": "What do auditors get that they can independently verify?",
      "a": "They can verify the WPC hash reference, validate gateway receipts for model calls emitted by clawproxy, and review a proof bundle that links receipts and approval decisions to the run. This is stronger than a screenshot or a single system log because it preserves the chain of custody across the model boundary."
    },
    {
      "q": "Can this work with Microsoft approval experiences?",
      "a": "Yes, you can route the human decision through a Microsoft approval flow via official API, then store the decision artifact and payload hash back into the run record. Keep the enforcement in the agent execution layer so the external approval system is an input, not the control boundary."
    }
  ],
  "sources": [
    {
      "title": "FAQ for AI approvals - Microsoft Copilot Studio",
      "uri": "https://learn.microsoft.com/en-us/microsoft-copilot-studio/faqs-ai-approvals"
    },
    {
      "title": "Multistage and AI approvals in agent flows - Microsoft Copilot Studio",
      "uri": "https://learn.microsoft.com/en-us/microsoft-copilot-studio/flows-advanced-approvals"
    },
    {
      "title": "Amazon Bedrock AgentCore Policy: Control Agent-to-Tool Interactions",
      "uri": "https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/policy.html"
    },
    {
      "title": "Establishing Responsible AI Policies for AI Agents across ...",
      "uri": "https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ai-agents/responsible-ai-across-organization"
    },
    {
      "title": "Human-in-the-Loop with AG-UI",
      "uri": "https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/human-in-the-loop"
    }
  ],
  "model": "candidate-01",
  "generatedAt": "2026-02-11T11:05:39.382Z",
  "indexable": true
}