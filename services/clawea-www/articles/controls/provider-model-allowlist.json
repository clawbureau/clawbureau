{
  "slug": "controls/provider-model-allowlist",
  "title": "Provider and model allowlists for Agents | Policy-as-Code Control | Claw EA",
  "category": "controls",
  "html": "<p>Provider and model allowlists are a policy-as-code control that restricts which model providers and which exact model identifiers an agent is permitted to call at runtime. In Claw EA, you express the rule as a WPC (Work Policy Contract) and enforce it at the execution layer using CST (scoped token) and clawproxy, so the agent cannot bypass it with prompt tricks.</p>\n<p>This matters because prompt-only guardrails can be overwritten by prompt injection or by tool misuse. A permissioned execution layer fails closed: if the provider or model is not on the allowlist, the call does not happen and you get verifiable evidence of what was attempted.</p>\n\n<h2>Step-by-step runbook</h2>\n<ol>\n  <li>\n    <p>Pick the concrete set of allowed providers and models for the job. Write them down as exact identifiers you expect to see on the wire, for example “openrouter” plus a short list of OpenRouter model ids.</p>\n    <p>Do not start with “any model from provider X”. Start with the smallest list that supports the workload.</p>\n  </li>\n  <li>\n    <p>Encode the allowlist as a WPC (Work Policy Contract) and publish it to the WPC registry (served by clawcontrols). Treat the WPC hash as the stable reference for the policy version.</p>\n    <p>If you need different allowlists per environment, publish separate WPCs and keep the hashes distinct.</p>\n  </li>\n  <li>\n    <p>Issue a CST (scoped token) from clawscope for the agent run. Enable optional policy hash pinning so the CST is only valid when enforcing the specific WPC hash you intended.</p>\n    <p>This prevents “token reuse with a looser policy” when jobs are replayed or moved across environments.</p>\n  </li>\n  <li>\n    <p>Route model traffic through clawproxy and configure the agent runtime to use it as the model provider path. Claw EA supports OpenRouter via fal routed through clawproxy (shipped).</p>\n    <p>If you use other model vendors, integrate via official API or via an MCP server, then enforce the allowlist at the proxy boundary as part of an enterprise buildout.</p>\n  </li>\n  <li>\n    <p>In OpenClaw (baseline agent runtime), keep local tool policy tight so the agent cannot introduce an alternate model client path. Use tool allowlists and sandboxing to reduce the chance of “side channel HTTP” to a provider endpoint.</p>\n    <p>OpenClaw’s configuration model separates sandboxing (where tools run) from tool policy (which tools exist), which is useful when you want network-facing tools disabled by default.</p>\n  </li>\n  <li>\n    <p>Run the job and collect the proof bundle produced by the harness. Ensure gateway receipts are present for each model call and that the receipts bind provider, model id, and job context.</p>\n    <p>Store the resulting artifact in Trust Pulse when you need a stable audit/viewing location.</p>\n  </li>\n</ol>\n\n<h2>Threat model</h2>\n<table>\n  <thead>\n    <tr>\n      <th>Threat</th>\n      <th>What happens</th>\n      <th>Control</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Model swapping</td>\n      <td>An agent silently switches from an approved model to a higher-risk or non-reviewed model with different behavior.</td>\n      <td>WPC allowlists exact provider and model identifiers; clawproxy rejects calls outside the list and emits gateway receipts for approved calls.</td>\n    </tr>\n    <tr>\n      <td>Provider switching to bypass governance</td>\n      <td>An agent routes calls to a different provider to evade logging, content policy, or cost expectations.</td>\n      <td>Execution uses a permissioned path: CST is issued for the job and can pin the WPC hash; clawproxy enforces provider allowlist at the gateway boundary.</td>\n    </tr>\n    <tr>\n      <td>Prompt injection disables “rules”</td>\n      <td>A malicious input convinces the agent to ignore system instructions and call an unapproved model.</td>\n      <td>Prompt text is not the enforcement point; the enforcement point is the proxy plus CST scope hash and pinned policy hash.</td>\n    </tr>\n    <tr>\n      <td>Shadow client inside tools</td>\n      <td>The agent uses a general-purpose HTTP tool or shell to call a provider API directly, bypassing the proxy.</td>\n      <td>OpenClaw tool policy reduces available network tools; sandboxing limits filesystem and process access. For stricter environments, egress allowlists enforced outside clawproxy are optional and can be implemented.</td>\n    </tr>\n    <tr>\n      <td>Replay of a permissive token</td>\n      <td>An attacker reuses an old token to run the same agent with a looser allowlist.</td>\n      <td>Marketplace anti-replay binding uses job-scoped CST binding (shipped). Policy hash pinning ties the CST to the intended WPC.</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>Policy-as-code example</h2>\n<p>The core idea is that the allowlist is an auditable artifact (WPC) and the runtime authorization (CST) is bound to it. Keep the policy strict: list allowed providers, list exact allowed models, and require proxy mediation for model calls.</p>\n<pre>\n{\n  \"wpc_version\": \"v1\",\n  \"control\": \"provider_model_allowlist\",\n  \"allowed\": {\n    \"providers\": [\n      \"openrouter_via_fal\"\n    ],\n    \"models\": [\n      \"openrouter:anthropic/claude-3.5-sonnet\",\n      \"openrouter:openai/gpt-4o-mini\"\n    ]\n  },\n  \"requirements\": {\n    \"model_calls_must_route_via\": \"clawproxy\",\n    \"deny_on_unknown_model\": true\n  },\n  \"audit\": {\n    \"require_gateway_receipts\": true,\n    \"bundle_on_job_close\": true\n  }\n}\n\n/* CST issuance intent (conceptual) */\n{\n  \"cst\": {\n    \"scope_hash\": \"sha256:...\",\n    \"pinned_wpc_hash\": \"b64u:... (optional policy hash pinning)\"\n  }\n}\n</pre>\n<p>In OpenClaw, treat this as complementary to local tool policy. You still want OpenClaw tool allowlists and sandboxing configured so the agent cannot easily create a second route to the internet that bypasses the proxy boundary.</p>\n\n<h2>What proof do you get?</h2>\n<p>For each model call routed through clawproxy, you get gateway receipts that can be verified later. These receipts are designed to be concrete evidence of which provider and model were invoked, under which job context, and under which authorization.</p>\n<p>At the end of the run, Claw EA produces a proof bundle that aggregates the relevant receipts and metadata needed for audit and verification. When you publish the artifact to Trust Pulse, reviewers can inspect the run without relying on the agent’s self-reported logs.</p>\n\n<h2>Rollback posture</h2>\n<table>\n  <thead>\n    <tr>\n      <th>Action</th>\n      <th>Safe rollback</th>\n      <th>Evidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Tighten the model allowlist in the WPC</td>\n      <td>Publish a new WPC hash with fewer models, then issue new CSTs pinned to the new hash. Leave old jobs verifiable by retaining old WPCs.</td>\n      <td>WPC hash history plus proof bundles showing which hash was enforced for each job.</td>\n    </tr>\n    <tr>\n      <td>Revoke an in-flight CST</td>\n      <td>Revoke via clawscope and rerun the job with a new CST. This is the quickest way to stop a run that is repeatedly attempting denied models.</td>\n      <td>Gateway receipts stop for that job context; revocation records support incident review.</td>\n    </tr>\n    <tr>\n      <td>Remove a provider from allowed providers</td>\n      <td>Publish a replacement WPC removing the provider and rotate the job configuration to only use the remaining approved provider paths.</td>\n      <td>Receipts show provider value per call, so you can confirm the provider is no longer used.</td>\n    </tr>\n    <tr>\n      <td>Investigate a suspected bypass via tools</td>\n      <td>Temporarily disable general network tools in OpenClaw tool policy and rerun in sandbox mode “all” while you diagnose.</td>\n      <td>OpenClaw security audit output plus proof bundles demonstrating model calls still went through clawproxy.</td>\n    </tr>\n  </tbody>\n</table>\n<p>If you need network-level egress allowlists, that is optional and can be implemented outside clawproxy. Treat it as a separate control that hardens the “shadow client” class of failures.</p>\n\n<h2>FAQ</h2>\n<h3>Why is prompt-only “use model X” not enough?</h3>\n<p>Because prompts are not an enforcement boundary. An attacker can inject text that changes instructions, or the agent can take a tool path that ignores the prompt and calls another model anyway.</p>\n<p>With a WPC plus CST and clawproxy enforcement, the call is blocked even if the agent asks for it, and you get receipts showing what was allowed.</p>\n\n<h3>What should I allowlist: model families or exact model ids?</h3>\n<p>Allowlist exact model ids. Families and aliases are where accidental drift happens, especially when providers introduce new revisions under similar names.</p>\n<p>If you need flexibility, publish a new WPC when you approve a new model, then pin new CSTs to that WPC hash.</p>\n\n<h3>How does this relate to OpenClaw tool policy and sandboxing?</h3>\n<p>They cover different failure modes. OpenClaw tool policy and sandboxing reduce what the agent can do locally, while provider and model allowlists constrain what the agent can do over model calls.</p>\n<p>Use both: local policy to reduce bypass routes, and clawproxy enforcement to make model usage verifiable.</p>\n\n<h3>Can I enforce this for Azure-hosted models or other vendors?</h3>\n<p>Yes, but do not assume native connectors. Integrate via official API or via an MCP server, then enforce the allowlist at the proxy boundary as an enterprise buildout.</p>\n<p>Microsoft platforms also support their own governance controls and guardrails; treat those as complementary, not a substitute for execution-layer enforcement.</p>\n\n<h3>What do auditors actually review?</h3>\n<p>They review the WPC hash, the CST binding, and the gateway receipts inside the proof bundle. This gives a verifiable trail of which model calls happened under which policy.</p>\n<p>Trust Pulse can be used as the stored artifact location for audit and viewing.</p>\n\n<h2>Sources</h2>\n<ul>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/sandbox-vs-tool-policy-vs-elevated.md\">OpenClaw: Sandbox vs Tool Policy vs Elevated</a></li>\n  <li><a href=\"https://github.com/openclaw/openclaw/blob/5d4f42016f3afdbd5218843648d3ea594541dedc/docs/gateway/security/index.md\">OpenClaw Gateway Security</a></li>\n  <li><a href=\"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-built-in-policy-model-deployment?view=azureml-api-2\">Control AI model deployment with built-in policies in Azure Machine Learning</a></li>\n  <li><a href=\"https://learn.microsoft.com/en-us/azure/ai-foundry/guardrails/guardrails-overview?view=foundry\">Guardrails and controls overview in Microsoft Foundry</a></li>\n</ul>",
  "description": "Provider and model allowlists are a policy-as-code control that restricts which model providers and which exact model identifiers an agent is permitted to call at runtime. In Claw EA, you express the rule as a WPC (Work ",
  "faqs": [
    {
      "q": "Why is prompt-only “use model X” not enough?",
      "a": "Because prompts are not an enforcement boundary. An attacker can inject text that changes instructions, or the agent can take a tool path that ignores the prompt and calls another model anyway."
    },
    {
      "q": "What should I allowlist: model families or exact model ids?",
      "a": "Allowlist exact model ids. Families and aliases are where accidental drift happens, especially when providers introduce new revisions under similar names."
    },
    {
      "q": "How does this relate to OpenClaw tool policy and sandboxing?",
      "a": "They cover different failure modes. OpenClaw tool policy and sandboxing reduce what the agent can do locally, while provider and model allowlists constrain what the agent can do over model calls."
    },
    {
      "q": "Can I enforce this for Azure-hosted models or other vendors?",
      "a": "Yes, but do not assume native connectors. Integrate via official API or via an MCP server, then enforce the allowlist at the proxy boundary as an enterprise buildout."
    },
    {
      "q": "What do auditors actually review?",
      "a": "They review the WPC hash, the CST binding, and the gateway receipts inside the proof bundle. This gives a verifiable trail of which model calls happened under which policy."
    }
  ],
  "sources": [
    {
      "title": "Managing GitHub Copilot coding agent in your enterprise",
      "uri": "https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/administer-copilot/manage-for-enterprise/manage-agents/manage-copilot-coding-agent"
    },
    {
      "title": "Control AI model deployment with built-in policies in Azure Machine Learning",
      "uri": "https://learn.microsoft.com/en-us/azure/machine-learning/how-to-built-in-policy-model-deployment?view=azureml-api-2"
    },
    {
      "title": "Guardrails and controls overview in Microsoft Foundry - Microsoft Foundry",
      "uri": "https://learn.microsoft.com/en-us/azure/ai-foundry/guardrails/guardrails-overview?view=foundry"
    },
    {
      "title": "Train a Smart Reply model & manage allowlists",
      "uri": "https://cloud.google.com/agent-assist/docs/model-training"
    },
    {
      "title": "Control access to Model Garden models",
      "uri": "https://cloud.google.com/vertex-ai/generative-ai/docs/control-model-access"
    }
  ],
  "model": "candidate-01",
  "generatedAt": "2026-02-11T11:12:34.491Z",
  "indexable": true
}